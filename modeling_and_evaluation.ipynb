{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e0fa48-7455-40ea-b3ab-e37efd3e7048",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d59145-624c-4181-803a-67e34369741d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "# Load handcrafted features\n",
    "mesh = gpd.read_file(\"/path/to/your/data/data.gpkg\")\n",
    "\n",
    "# Label assignment\n",
    "mesh[\"label\"] = np.where(\n",
    "    (mesh[\"vegetation\"] <= 0.95)\n",
    "    & (mesh[\"ghsl\"] >= 0.5)\n",
    "    & (mesh[\"osm\"] <= 0.5)\n",
    "    & (mesh[\"favelas\"] > 0.9),\n",
    "    1,\n",
    "    np.where(\n",
    "        (mesh[\"vegetation\"] <= 0.95)\n",
    "        & (mesh[\"ghsl\"] >= 0.5)\n",
    "        & (mesh[\"osm\"] <= 0.5)\n",
    "        & (mesh[\"favelas\"] == 0),\n",
    "        0,\n",
    "        np.nan,\n",
    "    ),\n",
    ")\n",
    "\n",
    "# Filter valid labeled samples\n",
    "dataset = mesh[mesh[\"label\"].notna()].copy()\n",
    "\n",
    "# Load zones shapefile\n",
    "zones = gpd.read_file(\"/path/to/your/data/zones.shp\")\n",
    "\n",
    "# Compute centroids and perform spatial join with zones\n",
    "dataset[\"centroid\"] = dataset.geometry.centroid\n",
    "points_zones = gpd.sjoin(\n",
    "    dataset.set_geometry(\"centroid\"),\n",
    "    zones[[\"fid\", \"geometry\"]],\n",
    "    how=\"left\",\n",
    "    predicate=\"within\",\n",
    ")\n",
    "dataset[\"zone\"] = points_zones[\"fid\"]\n",
    "dataset = dataset.drop(columns=[\"centroid\"])\n",
    "dataset = dataset[dataset[\"zone\"].notna()]\n",
    "\n",
    "# Load precomputed deep features\n",
    "with open(\"/path/to/your/data/deep_features.pkl\", \"rb\") as f:\n",
    "    features, ids = pickle.load(f)\n",
    "\n",
    "# Ensure ID type consistency\n",
    "id_type = type(dataset[\"id\"].iloc[0])\n",
    "ids = [id_type(i) for i in ids]\n",
    "\n",
    "# Map deep learning features to dataset entries\n",
    "id_to_features = dict(zip(ids, features))\n",
    "dataset[\"dl_features\"] = dataset[\"id\"].map(id_to_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a68b17-9ff0-4c75-8af2-1db726aceedb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Cross-validation: single view with deep features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "365a35f7-bdaa-40a8-b0be-b87ba07755d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.utils import resample\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, cohen_kappa_score\n",
    "\n",
    "zones = dataset['zone'].unique().tolist()\n",
    "zones.reverse()\n",
    "\n",
    "f1_scores = [[] for _ in range(len(zones))]\n",
    "precision_scores = [[] for _ in range(len(zones))]\n",
    "recall_scores = [[] for _ in range(len(zones))]\n",
    "kappa_scores = [[] for _ in range(len(zones))]\n",
    "\n",
    "for _ in range(10):\n",
    "    folds = []\n",
    "    for z in zones:\n",
    "        dataset_zone = dataset[dataset['zone'] == z]\n",
    "        X, y = np.array(dataset_zone['dl_features'].tolist()), dataset_zone['label'].values\n",
    "\n",
    "        class_0 = X[y == 0]\n",
    "        class_1 = X[y == 1]\n",
    "\n",
    "        if len(class_0) > len(class_1):\n",
    "            class_0_downsampled = resample(class_0, replace=False, n_samples=len(class_1))\n",
    "            X_balanced = np.vstack([class_0_downsampled, class_1])\n",
    "            y_balanced = np.hstack([np.zeros(len(class_0_downsampled)), np.ones(len(class_1))])\n",
    "        else:\n",
    "            class_1_downsampled = resample(class_1, replace=False, n_samples=len(class_0))\n",
    "            X_balanced = np.vstack([class_0, class_1_downsampled])\n",
    "            y_balanced = np.hstack([np.zeros(len(class_0)), np.ones(len(class_1_downsampled))])\n",
    "\n",
    "        p = np.random.permutation(len(y_balanced))\n",
    "        X_balanced, y_balanced = X_balanced[p], y_balanced[p]\n",
    "\n",
    "        folds.append([X_balanced, y_balanced])\n",
    "\n",
    "    for i in range(len(folds)):\n",
    "        X_test, y_test = folds[i][0], folds[i][1]\n",
    "\n",
    "        X_train = np.vstack([fold[0] for j, fold in enumerate(folds) if j != i])\n",
    "        y_train = np.hstack([fold[1] for j, fold in enumerate(folds) if j != i])\n",
    "\n",
    "        clf = RandomForestClassifier()\n",
    "        clf.fit(X_train, y_train)\n",
    "\n",
    "        y_pred = clf.predict(X_test)\n",
    "\n",
    "        precision_scores[i].append(precision_score(y_test, y_pred))\n",
    "        recall_scores[i].append(recall_score(y_test, y_pred))\n",
    "        f1_scores[i].append(f1_score(y_test, y_pred))\n",
    "        kappa_scores[i].append(cohen_kappa_score(y_test, y_pred))\n",
    "\n",
    "for i in range(len(zones)):\n",
    "    print(f\"Precision zone {i+1}: {np.mean(precision_scores[i]):.2f} +/- {np.std(precision_scores[i]):.2f}\")\n",
    "    print(f\"Recall zone {i+1}: {np.mean(recall_scores[i]):.2f} +/- {np.std(recall_scores[i]):.2f}\")\n",
    "    print(f\"F1-score zone {i+1}: {np.mean(f1_scores[i]):.2f} +/- {np.std(f1_scores[i]):.2f}\")\n",
    "    print(f\"Kappa zone {i+1}: {np.mean(kappa_scores[i]):.2f} +/- {np.std(kappa_scores[i]):.2f}\\n\")\n",
    "\n",
    "print(f\"Precision: {np.mean([np.mean(f) for f in precision_scores]):.2f} +/- {np.std([np.mean(f) for f in precision_scores]):.2f}\")\n",
    "print(f\"Recall: {np.mean([np.mean(f) for f in recall_scores]):.2f} +/- {np.std([np.mean(f) for f in recall_scores]):.2f}\")\n",
    "print(f\"F1-score: {np.mean([np.mean(f) for f in f1_scores]):.2f} +/- {np.std([np.mean(f) for f in f1_scores]):.2f}\")\n",
    "print(f\"Kappa: {np.mean([np.mean(f) for f in kappa_scores]):.2f} +/- {np.std([np.mean(f) for f in kappa_scores]):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba3673b-53b9-4d87-a7e4-ee56ec4c64b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Cross-validation: early fusion baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0599103b-4950-4e39-a716-0e2e626e991b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.utils import resample\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, cohen_kappa_score\n",
    "\n",
    "zones = dataset['zone'].unique().tolist()\n",
    "zones.reverse()\n",
    "\n",
    "f_cols = ['slope', 'profile_co', 'nodes', 'roads', 'mean_conne', 'min_connex', 'max_connex']\n",
    "\n",
    "f1_scores = [[] for _ in range(len(zones))]\n",
    "precision_scores = [[] for _ in range(len(zones))]\n",
    "recall_scores = [[] for _ in range(len(zones))]\n",
    "kappa_scores = [[] for _ in range(len(zones))]\n",
    "\n",
    "for _ in range(10):\n",
    "    folds = []\n",
    "    for z in zones:\n",
    "        dataset_zone = dataset[dataset['zone'] == z]\n",
    "        X, y = np.hstack(\n",
    "            (dataset_zone[f_cols].values, np.array(dataset_zone['dl_features'].tolist()))\n",
    "        ), dataset_zone['label'].values\n",
    "\n",
    "        class_0 = X[y == 0]\n",
    "        class_1 = X[y == 1]\n",
    "\n",
    "        if len(class_0) > len(class_1):\n",
    "            class_0_downsampled = resample(class_0, replace=False, n_samples=len(class_1))\n",
    "            X_balanced = np.vstack([class_0_downsampled, class_1])\n",
    "            y_balanced = np.hstack([np.zeros(len(class_0_downsampled)), np.ones(len(class_1))])\n",
    "        else:\n",
    "            class_1_downsampled = resample(class_1, replace=False, n_samples=len(class_0))\n",
    "            X_balanced = np.vstack([class_0, class_1_downsampled])\n",
    "            y_balanced = np.hstack([np.zeros(len(class_0)), np.ones(len(class_1_downsampled))])\n",
    "\n",
    "        p = np.random.permutation(len(y_balanced))\n",
    "        X_balanced, y_balanced = X_balanced[p], y_balanced[p]\n",
    "\n",
    "        folds.append([X_balanced, y_balanced])\n",
    "\n",
    "    for i in range(len(folds)):\n",
    "        X_test, y_test = folds[i][0], folds[i][1]\n",
    "\n",
    "        X_train = np.vstack([fold[0] for j, fold in enumerate(folds) if j != i])\n",
    "        y_train = np.hstack([fold[1] for j, fold in enumerate(folds) if j != i])\n",
    "\n",
    "        clf = RandomForestClassifier()\n",
    "        clf.fit(X_train, y_train)\n",
    "\n",
    "        y_pred = clf.predict(X_test)\n",
    "\n",
    "        precision_scores[i].append(precision_score(y_test, y_pred))\n",
    "        recall_scores[i].append(recall_score(y_test, y_pred))\n",
    "        f1_scores[i].append(f1_score(y_test, y_pred))\n",
    "        kappa_scores[i].append(cohen_kappa_score(y_test, y_pred))\n",
    "\n",
    "for i in range(len(zones)):\n",
    "    print(f\"Precision zone {i+1}: {np.mean(precision_scores[i]):.2f} +/- {np.std(precision_scores[i]):.2f}\")\n",
    "    print(f\"Recall zone {i+1}: {np.mean(recall_scores[i]):.2f} +/- {np.std(recall_scores[i]):.2f}\")\n",
    "    print(f\"F1-score zone {i+1}: {np.mean(f1_scores[i]):.2f} +/- {np.std(f1_scores[i]):.2f}\")\n",
    "    print(f\"Kappa zone {i+1}: {np.mean(kappa_scores[i]):.2f} +/- {np.std(kappa_scores[i]):.2f}\\n\")\n",
    "\n",
    "print(f\"Precision: {np.mean([np.mean(f) for f in precision_scores]):.2f} +/- {np.std([np.mean(f) for f in precision_scores]):.2f}\")\n",
    "print(f\"Recall: {np.mean([np.mean(f) for f in recall_scores]):.2f} +/- {np.std([np.mean(f) for f in recall_scores]):.2f}\")\n",
    "print(f\"F1-score: {np.mean([np.mean(f) for f in f1_scores]):.2f} +/- {np.std([np.mean(f) for f in f1_scores]):.2f}\")\n",
    "print(f\"Kappa: {np.mean([np.mean(f) for f in kappa_scores]):.2f} +/- {np.std([np.mean(f) for f in kappa_scores]):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d1ca2b-ebef-4f95-bdfe-54b0cc02ff4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Cross-validation: late fusion (MUSICA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45553380-5968-49c5-927c-cfda01c39b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.utils import resample\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, cohen_kappa_score\n",
    "\n",
    "zones = dataset['zone'].unique().tolist()\n",
    "zones.reverse()\n",
    "\n",
    "f_cols = ['slope', 'profile_co', 'nodes', 'roads', 'mean_conne', 'min_connex', 'max_connex']\n",
    "\n",
    "f1_scores = [[] for _ in range(len(zones))]\n",
    "precision_scores = [[] for _ in range(len(zones))]\n",
    "recall_scores = [[] for _ in range(len(zones))]\n",
    "kappa_scores = [[] for _ in range(len(zones))]\n",
    "\n",
    "h_preds = [[] for _ in range(len(zones))]\n",
    "dl_preds = [[] for _ in range(len(zones))]\n",
    "labels = [[] for _ in range(len(zones))]\n",
    "\n",
    "for _ in range(10):\n",
    "    h_folds = []\n",
    "    dl_folds = []\n",
    "    for z in zones:\n",
    "        dataset_zone = dataset[dataset['zone'] == z]\n",
    "        handcrafted_X = dataset_zone[f_cols].values\n",
    "        dl_X = np.array(dataset_zone['dl_features'].tolist())\n",
    "        y = dataset_zone['label'].values\n",
    "\n",
    "        random_state = np.random.randint(1, 42)\n",
    "\n",
    "        # Balance handcrafted features\n",
    "        class_0 = handcrafted_X[y == 0]\n",
    "        class_1 = handcrafted_X[y == 1]\n",
    "        if len(class_0) > len(class_1):\n",
    "            class_0_downsampled = resample(class_0, replace=False, n_samples=len(class_1), random_state=random_state)\n",
    "            X_balanced = np.vstack([class_0_downsampled, class_1])\n",
    "            y_balanced = np.hstack([np.zeros(len(class_0_downsampled)), np.ones(len(class_1))])\n",
    "        else:\n",
    "            class_1_downsampled = resample(class_1, replace=False, n_samples=len(class_0), random_state=random_state)\n",
    "            X_balanced = np.vstack([class_0, class_1_downsampled])\n",
    "            y_balanced = np.hstack([np.zeros(len(class_0)), np.ones(len(class_1_downsampled))])\n",
    "        p = np.random.permutation(len(y_balanced))\n",
    "        X_balanced, y_balanced = X_balanced[p], y_balanced[p]\n",
    "        h_folds.append([X_balanced, y_balanced])\n",
    "\n",
    "        # Balance deep features\n",
    "        class_0 = dl_X[y == 0]\n",
    "        class_1 = dl_X[y == 1]\n",
    "        if len(class_0) > len(class_1):\n",
    "            class_0_downsampled = resample(class_0, replace=False, n_samples=len(class_1), random_state=random_state)\n",
    "            X_balanced = np.vstack([class_0_downsampled, class_1])\n",
    "            y_balanced = np.hstack([np.zeros(len(class_0_downsampled)), np.ones(len(class_1))])\n",
    "        else:\n",
    "            class_1_downsampled = resample(class_1, replace=False, n_samples=len(class_0), random_state=random_state)\n",
    "            X_balanced = np.vstack([class_0, class_1_downsampled])\n",
    "            y_balanced = np.hstack([np.zeros(len(class_0)), np.ones(len(class_1_downsampled))])\n",
    "        X_balanced, y_balanced = X_balanced[p], y_balanced[p]\n",
    "        dl_folds.append([X_balanced, y_balanced])\n",
    "\n",
    "    for i in range(len(h_folds)):\n",
    "        # Train handcrafted model\n",
    "        X_test, y_test = h_folds[i][0], h_folds[i][1]\n",
    "        X_train = np.vstack([fold[0] for j, fold in enumerate(h_folds) if j != i])\n",
    "        y_train = np.hstack([fold[1] for j, fold in enumerate(h_folds) if j != i])\n",
    "        clf = RandomForestClassifier()\n",
    "        clf.fit(X_train, y_train)\n",
    "        h_y_pred = clf.predict(X_test)\n",
    "        h_y_probas = np.take(clf.predict_proba(np.array(X_test)), 0, axis=1)\n",
    "\n",
    "        # Train deep features model\n",
    "        X_test, y_test = dl_folds[i][0], dl_folds[i][1]\n",
    "        X_train = np.vstack([fold[0] for j, fold in enumerate(dl_folds) if j != i])\n",
    "        y_train = np.hstack([fold[1] for j, fold in enumerate(dl_folds) if j != i])\n",
    "        clf = RandomForestClassifier()\n",
    "        clf.fit(X_train, y_train)\n",
    "        dl_y_pred = clf.predict(X_test)\n",
    "        dl_y_probas = np.take(clf.predict_proba(np.array(X_test)), 0, axis=1)\n",
    "\n",
    "        labels[i].append(y_test)\n",
    "        h_preds[i].append(h_y_pred.copy())\n",
    "        dl_preds[i].append(dl_y_pred.copy())\n",
    "\n",
    "        # Late fusion\n",
    "        epsilon = 1e-10\n",
    "        w_h = np.abs(0.5 - h_y_probas + epsilon)\n",
    "        w_dl = np.abs(0.5 - dl_y_probas + epsilon)\n",
    "        w_h_normalized = w_h / (w_h + w_dl)\n",
    "        w_dl_normalized = w_dl / (w_h + w_dl)\n",
    "\n",
    "        h_y_pred[h_y_pred == 0] = -1\n",
    "        dl_y_pred[dl_y_pred == 0] = -1\n",
    "        pred_combination = w_h_normalized * h_y_pred + w_dl_normalized * dl_y_pred\n",
    "        y_pred = (pred_combination >= 0).astype(int)\n",
    "\n",
    "        precision_scores[i].append(precision_score(y_test, y_pred))\n",
    "        recall_scores[i].append(recall_score(y_test, y_pred))\n",
    "        f1_scores[i].append(f1_score(y_test, y_pred))\n",
    "        kappa_scores[i].append(cohen_kappa_score(y_test, y_pred))\n",
    "\n",
    "for i in range(len(zones)):\n",
    "    print(f\"Precision zone {i+1}: {np.mean(precision_scores[i]):.2f} +/- {np.std(precision_scores[i]):.2f}\")\n",
    "    print(f\"Recall zone {i+1}: {np.mean(recall_scores[i]):.2f} +/- {np.std(recall_scores[i]):.2f}\")\n",
    "    print(f\"F1-score zone {i+1}: {np.mean(f1_scores[i]):.2f} +/- {np.std(f1_scores[i]):.2f}\")\n",
    "    print(f\"Kappa zone {i+1}: {np.mean(kappa_scores[i]):.2f} +/- {np.std(kappa_scores[i]):.2f}\\n\")\n",
    "\n",
    "print(f\"Precision: {np.mean([np.mean(f) for f in precision_scores]):.2f} +/- {np.std([np.mean(f) for f in precision_scores]):.2f}\")\n",
    "print(f\"Recall: {np.mean([np.mean(f) for f in recall_scores]):.2f} +/- {np.std([np.mean(f) for f in recall_scores]):.2f}\")\n",
    "print(f\"F1-score: {np.mean([np.mean(f) for f in f1_scores]):.2f} +/- {np.std([np.mean(f) for f in f1_scores]):.2f}\")\n",
    "print(f\"Kappa: {np.mean([np.mean(f) for f in kappa_scores]):.2f} +/- {np.std([np.mean(f) for f in kappa_scores]):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb844036-a27b-4908-bd64-994f38cdac13",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Visualization of prediction-label distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ae070d-4a22-46ca-92e5-4373e8d6b703",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "medC1 = dl_preds[1][0]\n",
    "medA1 = h_preds[1][0]\n",
    "labels1 = labels[1][0]\n",
    "\n",
    "pointsC1 = np.column_stack((medC1, labels1))\n",
    "unique_pointsC1, countsC1 = np.unique(pointsC1, axis=0, return_counts=True)\n",
    "xC1, yC1, sizesC1 = unique_pointsC1[:, 0], unique_pointsC1[:, 1], countsC1 * 300\n",
    "\n",
    "pointsA1 = np.column_stack((medA1, labels1))\n",
    "unique_pointsA1, countsA1 = np.unique(pointsA1, axis=0, return_counts=True)\n",
    "xA1, yA1, sizesA1 = unique_pointsA1[:, 0], unique_pointsA1[:, 1], countsA1 * 300\n",
    "\n",
    "medC2 = dl_preds[0][0]\n",
    "medA2 = h_preds[0][0]\n",
    "labels2 = labels[0][0]\n",
    "\n",
    "pointsC2 = np.column_stack((medC2, labels2))\n",
    "unique_pointsC2, countsC2 = np.unique(pointsC2, axis=0, return_counts=True)\n",
    "xC2, yC2, sizesC2 = unique_pointsC2[:, 0], unique_pointsC2[:, 1], countsC2 * 300\n",
    "\n",
    "pointsA2 = np.column_stack((medA2, labels2))\n",
    "unique_pointsA2, countsA2 = np.unique(pointsA2, axis=0, return_counts=True)\n",
    "xA2, yA2, sizesA2 = unique_pointsA2[:, 0], unique_pointsA2[:, 1], countsA2 * 300\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(8, 4))\n",
    "\n",
    "axs[0].scatter(xC1, yC1, s=sizesC1, color='#1f77b4', alpha=1, edgecolors=\"#1f77b4\", label='C')\n",
    "axs[0].scatter(xA1, yA1, s=sizesA1, color='#2ca02c', facecolors='none', edgecolors=\"#2ca02c\", label='A', linewidths=1.5)\n",
    "axs[0].set_xticks([0, 1])\n",
    "axs[0].set_xticklabels(['F', 'I'], fontsize=16)\n",
    "axs[0].set_yticks([0, 1])\n",
    "axs[0].set_yticklabels(['F', 'I'], fontsize=16)\n",
    "axs[0].set_xlim(0, 1)\n",
    "axs[0].set_ylim(0, 1)\n",
    "axs[0].set_xlabel('Prediction', fontsize=16, labelpad=-10)\n",
    "axs[0].set_ylabel('Label', fontsize=16, labelpad=-10)\n",
    "axs[0].set_aspect('equal')\n",
    "\n",
    "axs[1].scatter(xC2, yC2, s=sizesC2, color='#1f77b4', alpha=1, edgecolors=\"#1f77b4\")\n",
    "axs[1].scatter(xA2, yA2, s=sizesA2, color='#2ca02c', facecolors='none', edgecolors=\"#2ca02c\", linewidths=1.5)\n",
    "axs[1].set_xticks([0, 1])\n",
    "axs[1].set_xticklabels(['F', 'I'], fontsize=16)\n",
    "axs[1].set_yticks([0, 1])\n",
    "axs[1].set_yticklabels(['F', 'I'], fontsize=16)\n",
    "axs[1].set_xlim(0, 1)\n",
    "axs[1].set_ylim(0, 1)\n",
    "axs[1].set_xlabel('Prediction', fontsize=16, labelpad=-10)\n",
    "axs[1].set_ylabel('Label', fontsize=16, labelpad=-10)\n",
    "axs[1].set_aspect('equal')\n",
    "\n",
    "legend_elements = [\n",
    "    Line2D([1], [1], marker='o', color='w', label='Deep features', markerfacecolor='#1f77b4', markersize=18),\n",
    "    Line2D([1], [1], marker='o', color=\"#2ca02c\", label='Handcrafted features', markerfacecolor='none', markersize=16, markeredgewidth=1.5),\n",
    "]\n",
    "\n",
    "for ax in axs:\n",
    "    ax.tick_params(axis=\"both\", which=\"both\", labelsize=16)\n",
    "\n",
    "fig.legend(handles=legend_elements, loc=\"lower center\", bbox_to_anchor=(0.5, -0.15), fontsize=16, ncol=2)\n",
    "\n",
    "plt.savefig(\"comp.png\", dpi=300, bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
