{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee6cb889-201e-45f4-8974-f977ffa4ff49",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Prepare Sentinel-1 (SAR) and Sentinel-2 (optical) satellite images\n",
    "## Preprocessing script for projection and resampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4407061-9f93-46e1-be47-cccdccc1cf2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio\n",
    "from rasterio.warp import calculate_default_transform, reproject, Resampling\n",
    "from rasterio.crs import CRS\n",
    "\n",
    "\n",
    "# List of file paths for the 12 Sentinel-2 bands\n",
    "file_paths = [\n",
    "    \"/path/to/your/data/2020-08-11-00:00_2020-08-11-23:59_Sentinel-2_L2A_B01_(Raw).tiff\",\n",
    "    \"/path/to/your/data/2020-08-11-00:00_2020-08-11-23:59_Sentinel-2_L2A_B02_(Raw).tiff\",\n",
    "    \"/path/to/your/data/2020-08-11-00:00_2020-08-11-23:59_Sentinel-2_L2A_B03_(Raw).tiff\",\n",
    "    \"/path/to/your/data/2020-08-11-00:00_2020-08-11-23:59_Sentinel-2_L2A_B04_(Raw).tiff\",\n",
    "    \"/path/to/your/data/2020-08-11-00:00_2020-08-11-23:59_Sentinel-2_L2A_B05_(Raw).tiff\",\n",
    "    \"/path/to/your/data/2020-08-11-00:00_2020-08-11-23:59_Sentinel-2_L2A_B06_(Raw).tiff\",\n",
    "    \"/path/to/your/data/2020-08-11-00:00_2020-08-11-23:59_Sentinel-2_L2A_B07_(Raw).tiff\",\n",
    "    \"/path/to/your/data/2020-08-11-00:00_2020-08-11-23:59_Sentinel-2_L2A_B08_(Raw).tiff\",\n",
    "    \"/path/to/your/data/2020-08-11-00:00_2020-08-11-23:59_Sentinel-2_L2A_B8A_(Raw).tiff\",\n",
    "    \"/path/to/your/data/2020-08-11-00:00_2020-08-11-23:59_Sentinel-2_L2A_B09_(Raw).tiff\",\n",
    "    \"/path/to/your/data/2020-08-11-00:00_2020-08-11-23:59_Sentinel-2_L2A_B11_(Raw).tiff\",\n",
    "    \"/path/to/your/data/2020-08-11-00:00_2020-08-11-23:59_Sentinel-2_L2A_B12_(Raw).tiff\"\n",
    "]\n",
    "\n",
    "'''\n",
    "# List of file paths for Sentinel-1 VV and VH band paths\n",
    "file_paths = [\n",
    "    \"/path/to/your/data/2019-03-30-00:00_2019-03-30-23:59_Sentinel-1_IW_VV+VH_VV_(Raw).tiff\",\n",
    "    \"/path/to/your/data/2019-03-30-00:00_2019-03-30-23:59_Sentinel-1_IW_VV+VH_VH_(Raw).tiff\"\n",
    "]\n",
    "'''\n",
    "\n",
    "\n",
    "def get_resolution(file_path):\n",
    "    \"\"\"\n",
    "    Get the spatial resolution (pixel size) of a TIFF file.\n",
    "\n",
    "    Parameters:\n",
    "        file_path (str): Path to the raster file.\n",
    "\n",
    "    Returns:\n",
    "        tuple: (resolution_x, resolution_y) in meters.\n",
    "    \"\"\"\n",
    "    with rasterio.open(file_path) as src:\n",
    "        return src.res\n",
    "\n",
    "\n",
    "def project_raster(input_file, output_file, target_crs):\n",
    "    \"\"\"\n",
    "    Reproject a raster to a specified coordinate reference system (CRS).\n",
    "\n",
    "    Parameters:\n",
    "        input_file (str): Path to the input raster.\n",
    "        output_file (str): Path to the output reprojected raster.\n",
    "        target_crs (CRS): Target coordinate reference system.\n",
    "    \"\"\"\n",
    "    with rasterio.open(input_file) as src:\n",
    "        transform, width, height = calculate_default_transform(\n",
    "            src.crs, target_crs, src.width, src.height, *src.bounds\n",
    "        )\n",
    "\n",
    "        kwargs = src.meta.copy()\n",
    "        kwargs.update({\n",
    "            \"crs\": target_crs,\n",
    "            \"transform\": transform,\n",
    "            \"width\": width,\n",
    "            \"height\": height\n",
    "        })\n",
    "\n",
    "        with rasterio.open(output_file, \"w\", **kwargs) as dst:\n",
    "            for i in range(1, src.count + 1):\n",
    "                reproject(\n",
    "                    source=rasterio.band(src, i),\n",
    "                    destination=rasterio.band(dst, i),\n",
    "                    src_transform=src.transform,\n",
    "                    src_crs=src.crs,\n",
    "                    dst_transform=transform,\n",
    "                    dst_crs=target_crs,\n",
    "                    resampling=Resampling.nearest\n",
    "                )\n",
    "\n",
    "\n",
    "def resample_raster(input_file, output_file, target_res_x, target_res_y):\n",
    "    \"\"\"\n",
    "    Resample a raster to a specified spatial resolution.\n",
    "\n",
    "    Parameters:\n",
    "        input_file (str): Path to the input raster.\n",
    "        output_file (str): Path to the output resampled raster.\n",
    "        target_res_x (float): Desired pixel width in meters.\n",
    "        target_res_y (float): Desired pixel height in meters.\n",
    "    \"\"\"\n",
    "    with rasterio.open(input_file) as src:\n",
    "        transform = rasterio.Affine(\n",
    "            target_res_x, 0.0, src.bounds.left, 0.0, -target_res_y, src.bounds.top\n",
    "        )\n",
    "        width = int((src.bounds.right - src.bounds.left) / target_res_x)\n",
    "        height = int((src.bounds.top - src.bounds.bottom) / target_res_y)\n",
    "\n",
    "        kwargs = src.meta.copy()\n",
    "        kwargs.update({\n",
    "            \"transform\": transform,\n",
    "            \"width\": width,\n",
    "            \"height\": height,\n",
    "            \"dtype\": \"float32\"\n",
    "        })\n",
    "\n",
    "        with rasterio.open(output_file, \"w\", **kwargs) as dst:\n",
    "            for i in range(1, src.count + 1):\n",
    "                reproject(\n",
    "                    source=rasterio.band(src, i),\n",
    "                    destination=rasterio.band(dst, i),\n",
    "                    src_transform=src.transform,\n",
    "                    src_crs=src.crs,\n",
    "                    dst_transform=transform,\n",
    "                    dst_crs=src.crs,\n",
    "                    resampling=Resampling.bilinear\n",
    "                )\n",
    "\n",
    "\n",
    "for path in file_paths:\n",
    "    res_x, res_y = get_resolution(path)\n",
    "    print(f\"Spatial resolution of {path.split('/')[-1]}: {res_x}m x {res_y}m\")\n",
    "\n",
    "for path in file_paths:\n",
    "    output_path = f\"{path.split('.')[0]}_proj.tiff\"\n",
    "    project_raster(path, output_path, CRS.from_epsg(32723))\n",
    "\n",
    "for path in file_paths:\n",
    "    projected_path = f\"{path.split('.')[0]}_proj.tiff\"\n",
    "    res_x, res_y = get_resolution(projected_path)\n",
    "    print(f\"Projected resolution of {projected_path.split('/')[-1]}: {res_x}m x {res_y}m\")\n",
    "\n",
    "for path in file_paths:\n",
    "    projected_path = f\"{path.split('.')[0]}_proj.tiff\"\n",
    "    output_resampled_path = f\"{projected_path.split('.')[0]}_10m.tiff\"\n",
    "    resample_raster(projected_path, output_resampled_path, 10, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f947d52a-5295-469b-a93d-144dac65ef58",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Raster tiling and feature extraction with CROMA\n",
    "## Requires code and weights from https://github.com/antofuller/CROMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e8d2191-a2d1-4cfe-a571-e400128534bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import rasterio\n",
    "from rasterio.windows import Window\n",
    "import os\n",
    "\n",
    "\n",
    "class Cutter:\n",
    "    \"\"\"\n",
    "    Cut a raster image into smaller tiles based on a vector grid.\n",
    "\n",
    "    Attributes:\n",
    "        vector_file (str): Path to the shapefile containing the grid cells.\n",
    "        raster_file (str): Path to the raster image to be split.\n",
    "        output_folder (str): Folder where the tiles will be saved.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, vector_file, raster_file, output_folder):\n",
    "        self.vector_file = vector_file\n",
    "        self.raster_file = raster_file\n",
    "        self.output_folder = output_folder\n",
    "\n",
    "    def cut_images(self):\n",
    "        \"\"\"\n",
    "        Read the input raster and vector grid, then export one raster patch per polygon.\n",
    "        Each patch corresponds to the bounds of a single grid cell.\n",
    "        \"\"\"\n",
    "        grid = gpd.read_file(self.vector_file)\n",
    "        gdf = gpd.GeoDataFrame(geometry=grid.geometry)\n",
    "        gdf[\"id\"] = grid[\"id\"]\n",
    "\n",
    "        with rasterio.open(self.raster_file) as src:\n",
    "            for _, row in grid.iterrows():\n",
    "                cell_id = row[\"id\"]\n",
    "                geom = row.geometry\n",
    "\n",
    "                window = src.window(*geom.bounds)\n",
    "                subset = src.read(window=window)\n",
    "\n",
    "                profile = src.profile\n",
    "                profile.update({\n",
    "                    \"height\": window.height,\n",
    "                    \"width\": window.width,\n",
    "                    \"transform\": rasterio.windows.transform(window, src.transform)\n",
    "                })\n",
    "\n",
    "                os.makedirs(self.output_folder, exist_ok=True)\n",
    "\n",
    "                output_path = os.path.join(self.output_folder, f\"{cell_id}.tif\")\n",
    "                with rasterio.open(output_path, \"w\", **profile) as dst:\n",
    "                    dst.write(subset)\n",
    "\n",
    "        gdf.to_file(os.path.join(self.output_folder, \"check\"))\n",
    "\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import VisionDataset\n",
    "import imageio.v2 as imageio\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "\n",
    "class Loader:\n",
    "    \"\"\"\n",
    "    Prepare paired optical and SAR image datasets for feature extraction.\n",
    "\n",
    "    Attributes:\n",
    "        opt_root_dir (str): Directory containing optical image patches.\n",
    "        sar_root_dir (str): Directory containing SAR image patches.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, opt_root_dir, sar_root_dir):\n",
    "        self.opt_root_dir = opt_root_dir\n",
    "        self.sar_root_dir = sar_root_dir\n",
    "\n",
    "    def load_data(self, sample_size=224, batch_size=32):\n",
    "        \"\"\"\n",
    "        Create a PyTorch DataLoader from paired optical and SAR images.\n",
    "\n",
    "        Parameters:\n",
    "            sample_size (int): Resize dimension for the images.\n",
    "            batch_size (int): Number of samples per batch.\n",
    "        \"\"\"\n",
    "        class CustomDataset(VisionDataset):\n",
    "            \"\"\"Custom paired dataset for optical and SAR images.\"\"\"\n",
    "\n",
    "            def __init__(self, opt_root, sar_root, transform=None, target_transform=None):\n",
    "                super(CustomDataset, self).__init__(\n",
    "                    root=opt_root, transform=transform, target_transform=target_transform\n",
    "                )\n",
    "                self.opt_root = opt_root\n",
    "                self.sar_root = sar_root\n",
    "                self.transform = transform\n",
    "\n",
    "                self.samples = []\n",
    "                opt_images = [\n",
    "                    img_name for img_name in os.listdir(opt_root)\n",
    "                    if os.path.isfile(os.path.join(opt_root, img_name))\n",
    "                ]\n",
    "                for img_name in opt_images:\n",
    "                    opt_img_path = os.path.join(opt_root, img_name)\n",
    "                    sar_img_path = os.path.join(sar_root, img_name)\n",
    "                    self.samples.append((opt_img_path, sar_img_path))\n",
    "\n",
    "            def __len__(self):\n",
    "                return len(self.samples)\n",
    "\n",
    "            def __getitem__(self, idx):\n",
    "                opt_img_path, sar_img_path = self.samples[idx]\n",
    "                opt_img = imageio.imread(opt_img_path)\n",
    "                sar_img = imageio.imread(sar_img_path)\n",
    "                opt_img = np.transpose(opt_img, (2, 0, 1)).astype(np.float32)\n",
    "                sar_img = np.transpose(sar_img, (2, 0, 1)).astype(np.float32)\n",
    "                opt_img = torch.tensor(opt_img)\n",
    "                sar_img = torch.tensor(sar_img)\n",
    "                if self.transform:\n",
    "                    opt_img = self.transform(opt_img)\n",
    "                    sar_img = self.transform(sar_img)\n",
    "                return opt_img, sar_img, opt_img_path, sar_img_path\n",
    "\n",
    "        transform = transforms.Resize((sample_size, sample_size), antialias=True)\n",
    "        dataset = CustomDataset(\n",
    "            opt_root=self.opt_root_dir,\n",
    "            sar_root=self.sar_root_dir,\n",
    "            transform=transform\n",
    "        )\n",
    "        self.dataset = dataset\n",
    "        self.loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "import h5py\n",
    "import pickle\n",
    "from use_croma import PretrainedCROMA\n",
    "\n",
    "\n",
    "class FeatureExtractor:\n",
    "    \"\"\"\n",
    "    Extract deep multimodal features using a pretrained CROMA network.\n",
    "\n",
    "    Attributes:\n",
    "        dataloader (torch.utils.data.DataLoader): DataLoader providing paired images.\n",
    "        use_8_bit (bool): Whether to normalize to 8-bit before feeding the model.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, dataloader, use_8_bit=True):\n",
    "        self.dataloader = dataloader\n",
    "        self.use_8_bit = use_8_bit\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.FE = PretrainedCROMA(\n",
    "            pretrained_path=\"CROMA_base.pt\", size=\"base\", modality=\"both\", image_resolution=120\n",
    "        )\n",
    "        self.FE.to(self.device)\n",
    "        self.FE.eval()\n",
    "\n",
    "    def normalize(self, x):\n",
    "        \"\"\"\n",
    "        Normalize each image channel to either [0, 255] or [0, 1] based on use_8_bit.\n",
    "\n",
    "        Parameters:\n",
    "            x (torch.Tensor): Input tensor with shape (B, C, H, W).\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Normalized tensor.\n",
    "        \"\"\"\n",
    "        x = x.float()\n",
    "        imgs = []\n",
    "        for channel in range(x.shape[1]):\n",
    "            mean = x[:, channel, :, :].mean()\n",
    "            std = x[:, channel, :, :].std()\n",
    "            min_val = mean - 2 * std\n",
    "            max_val = mean + 2 * std\n",
    "            if self.use_8_bit:\n",
    "                img = (x[:, channel, :, :] - min_val) / (max_val - min_val) * 255.0\n",
    "                img = torch.clip(img, 0, 255).unsqueeze(dim=1).to(torch.uint8)\n",
    "            else:\n",
    "                img = (x[:, channel, :, :] - min_val) / (max_val - min_val)\n",
    "                img = torch.clip(img, 0, 1).unsqueeze(dim=1)\n",
    "            imgs.append(img)\n",
    "        return torch.cat(imgs, dim=1)\n",
    "\n",
    "    def extract_features(self, save_name=None):\n",
    "        \"\"\"\n",
    "        Extract features for each image pair and optionally save them to disk.\n",
    "\n",
    "        Parameters:\n",
    "            save_name (str): Optional base name for the output files (.h5 and .pkl).\n",
    "\n",
    "        Returns:\n",
    "            tuple: (features, ids)\n",
    "        \"\"\"\n",
    "        features_batches = []\n",
    "        id_batches = []\n",
    "        with torch.no_grad():\n",
    "            for optical_images, sar_images, optical_img_paths, _ in tqdm(\n",
    "                self.dataloader, desc=\"Extracting Features\"\n",
    "            ):\n",
    "                optical_images = self.normalize(optical_images.to(self.device))\n",
    "                sar_images = self.normalize(sar_images.to(self.device))\n",
    "                if self.use_8_bit:\n",
    "                    optical_images = optical_images.float() / 255\n",
    "                    sar_images = sar_images.float() / 255\n",
    "                outputs = self.FE(\n",
    "                    SAR_images=sar_images, optical_images=optical_images\n",
    "                )[\"joint_GAP\"]\n",
    "                features_batches.append(outputs.cpu())\n",
    "                ids_i = torch.tensor([\n",
    "                    int((path.split(\".\")[0]).split(\"/\")[-1])\n",
    "                    for path in optical_img_paths\n",
    "                ])\n",
    "                id_batches.append(ids_i)\n",
    "\n",
    "        features = torch.cat(features_batches).numpy()\n",
    "        ids = torch.cat(id_batches).numpy()\n",
    "\n",
    "        if save_name:\n",
    "            with h5py.File(f\"{save_name}.h5\", \"w\") as hf:\n",
    "                hf.create_dataset(\"features\", data=features)\n",
    "                hf.create_dataset(\"ids\", data=ids)\n",
    "\n",
    "            with open(f\"{save_name}.pkl\", \"wb\") as f:\n",
    "                pickle.dump([features, ids], f)\n",
    "\n",
    "        return features, ids\n",
    "\n",
    "\n",
    "# --- Execution pipeline ---\n",
    "\n",
    "cutter = Cutter(\n",
    "    \"/path/to/your/data/grid.shp\",\n",
    "    \"/path/to/your/data/sar_image.tif\",\n",
    "    \"/path/to/your/data/patchs_sar_image\"\n",
    ")\n",
    "cutter.cut_images()\n",
    "\n",
    "cutter = Cutter(\n",
    "    \"/path/to/your/data/grid.shp\",\n",
    "    \"/path/to/your/data/opt_image.tif\",\n",
    "    \"/path/to/your/data/patchs_opt_image\"\n",
    ")\n",
    "cutter.cut_images()\n",
    "\n",
    "processor = Loader(\n",
    "    opt_root_dir=\"/path/to/your/data/patchs_opt_image\",\n",
    "    sar_root_dir=\"/path/to/your/data/patchs_sar_image\"\n",
    ")\n",
    "processor.load_data(sample_size=120, batch_size=16)\n",
    "loader = processor.loader\n",
    "\n",
    "feature_extractor = FeatureExtractor(dataloader=loader, use_8_bit=True)\n",
    "features, ids = feature_extractor.extract_features(\"dl_features\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
